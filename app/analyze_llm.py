# app/analyze_llm.py
# -*- coding: utf-8 -*-
from __future__ import annotations
import os, argparse, pandas as pd

from app.tools.youtube import fetch_comments, extract_video_id
from app.tools.preprocess import select_fast_batch, preprocess_comments_df
from app.tools.topics_taxonomy import TAXONOMY, ID2NAME
from app.tools.topics_llm import classify_llm_full, aggregate_topics, sample_quotes
from app.tools.classification_db import (
    load_classification_results, 
    get_topic_statistics, 
    get_video_list_with_classification,
    delete_classification_results
)

def run(url: str, sqlite_path: str, limit: int = 1200):
    """
    –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É YouTube –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ —á–µ—Ä–µ–∑ LLM –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—é.
    
    Args:
        url: YouTube URL –∞–±–æ video_id
        sqlite_path: –®–ª—è—Ö –¥–æ SQLite –∫–µ—à—É
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏
    
    Returns:
        tuple: (df_cls, top) - –∫–ª–∞—Å–∏—Ñ—ñ–∫–æ–≤–∞–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ —Ç–∞ —Ç–æ–ø —Ç–µ–º
    """
    print(f"üé¨ –ê–Ω–∞–ª—ñ–∑ YouTube –≤—ñ–¥–µ–æ: {url}")
    print(f"üìä –û–±—Ä–æ–±–∫–∞ –¥–æ {limit} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤...")
    
    # 1) –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ/–∫–µ—à
    print("\n1Ô∏è‚É£ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤...")
    df_all = fetch_comments(url, sqlite_path=sqlite_path, include_replies=True, max_comments=5000)
    print(f"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {len(df_all)} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤")
    
    # 2) –®–≤–∏–¥–∫–∏–π —Ä–µ–∂–∏–º + –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–∏–Ω–≥
    print("\n2Ô∏è‚É£ –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å–∏–Ω–≥...")
    df_fast = select_fast_batch(df_all, mode="top_likes", limit=limit, include_replies=False)
    print(f"   –í—ñ–¥—ñ–±—Ä–∞–Ω–æ –¥–ª—è —à–≤–∏–¥–∫–æ—ó –æ–±—Ä–æ–±–∫–∏: {len(df_fast)} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤")
    
    df_pre = preprocess_comments_df(
        df_fast, 
        min_chars=12
        # keep_langs=None - –∑–∞–ª–∏—à–∞—î–º–æ –≤—Å—ñ –º–æ–≤–∏ –¥–ª—è LLM
    )
    print(f"   –ü—ñ—Å–ª—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–∏–Ω–≥—É: {len(df_pre)} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤")
    
    if len(df_pre) == 0:
        print("‚ö†Ô∏è  –ù–µ–º–∞—î –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –ø—ñ—Å–ª—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–∏–Ω–≥—É!")
        return pd.DataFrame(), pd.DataFrame()
    
    # 3) –ü–æ–≤–Ω–∞ LLM-–∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
    print("\n3Ô∏è‚É£ LLM –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è —á–µ—Ä–µ–∑ OpenRouter...")
    df_cls = classify_llm_full(df_pre, TAXONOMY, text_col="text_clean", batch_size=20)
    print(f"   –ö–ª–∞—Å–∏—Ñ—ñ–∫–æ–≤–∞–Ω–æ: {len(df_cls)} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤")
    
    # 4) –ê–≥—Ä–µ–≥–∞—Ü—ñ—è: Top-5
    print("\n4Ô∏è‚É£ –ê–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤...")
    top = aggregate_topics(df_cls).head(5)
    
    print(f"\nüèÜ –¢–æ–ø-{len(top)} —Ç–µ–º:")
    print("=" * 60)
    
    for i, (_, row) in enumerate(top.iterrows(), 1):
        topic_name = ID2NAME.get(row['topic_id'], row['topic_id'])
        print(f"{i}. {topic_name}: {int(row['count'])} ({row['share']*100:.1f}%)")
        
        # –ü–æ–∫–∞–∑—É—î–º–æ 2 –Ω–∞–π–∫—Ä–∞—â—ñ —Ü–∏—Ç–∞—Ç–∏ –¥–ª—è —Ü—ñ—î—ó —Ç–µ–º–∏
        quotes = sample_quotes(df_cls, row["topic_id"], k=2)
        for j, quote in enumerate(quotes, 1):
            text = (quote["text"] or "")[:160].replace("\n", " ")
            print(f"   {j}) {quote['comment_id']}: {text}")
        
        if i < len(top):
            print()  # –ü–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫ –º—ñ–∂ —Ç–µ–º–∞–º–∏
    
    print("=" * 60)
    print(f"‚úÖ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –û–±—Ä–æ–±–∞–Ω–æ {len(df_cls)} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤")
    
    return df_cls, top

def show_saved_results(video_url: str, sqlite_path: str):
    """–ü–æ–∫–∞–∑–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –¥–ª—è –≤—ñ–¥–µ–æ."""
    video_id = extract_video_id(video_url)
    if not video_id:
        print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏—Ç—è–≥—Ç–∏ video_id –∑ {video_url}")
        return
    
    print(f"üìä –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è –≤—ñ–¥–µ–æ {video_id}...")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ –ë–î
    df_saved = load_classification_results(video_id, sqlite_path)
    
    if df_saved.empty:
        print("‚ö†Ô∏è  –ó–±–µ—Ä–µ–∂–µ–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –°–ø–æ—á–∞—Ç–∫—É –∑–∞–ø—É—Å—Ç—ñ—Ç—å –∞–Ω–∞–ª—ñ–∑.")
        return
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = get_topic_statistics(video_id, sqlite_path)
    
    print(f"\n‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏:")
    print(f"   –í—Å—å–æ–≥–æ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –≤ –ë–î: {stats['total_in_db']}")
    print(f"   –ö–ª–∞—Å–∏—Ñ—ñ–∫–æ–≤–∞–Ω–æ: {stats['total_comments']} ({stats['classification_coverage']}%)")
    
    if stats['topics']:
        print(f"\nüèÜ –¢–æ–ø —Ç–µ–º (–∑ –ë–î):")
        for i, topic in enumerate(stats['topics'][:5], 1):
            topic_name = ID2NAME.get(topic['topic'], topic['topic'])
            print(f"{i}. {topic_name}: {topic['count']} ({topic['share_percent']}%)")
    
    # –ü–æ–∫–∞–∑—É—î–º–æ –∑—Ä–∞–∑–∫–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤
    classified_df = df_saved[df_saved['topic_top'].notna()]
    if not classified_df.empty:
        print(f"\nüí¨ –ó—Ä–∞–∑–∫–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–æ–≤–∞–Ω–∏—Ö –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤:")
        for topic in stats['topics'][:3]:
            topic_comments = classified_df[classified_df['topic_top'] == topic['topic']].head(2)
            topic_name = ID2NAME.get(topic['topic'], topic['topic'])
            print(f"\n   {topic_name}:")
            for _, comment in topic_comments.iterrows():
                text = (comment['text'] or "")[:150].replace("\n", " ")
                print(f"   ‚Ä¢ {text}...")

def list_analyzed_videos(sqlite_path: str):
    """–ü–æ–∫–∞–∑–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –≤—ñ–¥–µ–æ."""
    print("üìã –°–ø–∏—Å–æ–∫ –≤—ñ–¥–µ–æ –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö:")
    
    videos_df = get_video_list_with_classification(sqlite_path)
    
    if videos_df.empty:
        print("‚ö†Ô∏è  –ë–∞–∑–∞ –¥–∞–Ω–∏—Ö –ø–æ—Ä–æ–∂–Ω—è. –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π—Ç–µ —è–∫–µ—Å—å –≤—ñ–¥–µ–æ —Å–ø–æ—á–∞—Ç–∫—É.")
        return
    
    print(f"\n{'#':<3} {'Video ID':<15} {'–ö–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤':<12} {'–ö–ª–∞—Å–∏—Ñ—ñ–∫–æ–≤–∞–Ω–æ':<15} {'–ü–æ–∫—Ä–∏—Ç—Ç—è':<10} {'–û—Å—Ç–∞–Ω–Ω—ñ–π –∞–Ω–∞–ª—ñ–∑':<20}")
    print("-" * 80)
    
    for i, (_, row) in enumerate(videos_df.iterrows(), 1):
        coverage = f"{row['classification_coverage']:.1f}%" if row['classification_coverage'] > 0 else "0%"
        last_analysis = row['last_classified_at'][:19] if row['last_classified_at'] else "–ù—ñ–∫–æ–ª–∏"
        
        print(f"{i:<3} {row['video_id']:<15} {row['total_comments']:<12} {row['classified_comments']:<15} {coverage:<10} {last_analysis:<20}")

def clear_results(video_url: str = None, sqlite_path: str = "./.cache.db"):
    """–û—á–∏—Å—Ç–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó."""
    if video_url:
        video_id = extract_video_id(video_url)
        if not video_id:
            print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏—Ç—è–≥—Ç–∏ video_id –∑ {video_url}")
            return
        
        success = delete_classification_results(video_id, sqlite_path)
        if success:
            print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è –≤—ñ–¥–µ–æ {video_id} –æ—á–∏—â–µ–Ω–æ")
        else:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—á–∏—â–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è {video_id}")
    else:
        success = delete_classification_results(None, sqlite_path)
        if success:
            print("‚úÖ –í—Å—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –æ—á–∏—â–µ–Ω–æ")
        else:
            print("‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—á–∏—â–µ–Ω–Ω—è –≤—Å—ñ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")

def main():
    """CLI —Ç–æ—á–∫–∞ –≤—Ö–æ–¥—É."""
    parser = argparse.ArgumentParser(
        description="–ê–Ω–∞–ª—ñ–∑ YouTube –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ —á–µ—Ä–µ–∑ LLM –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—é",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–∫–ª–∞–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
  # –ù–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑
  python -m app.analyze_llm analyze "https://www.youtube.com/watch?v=26riTPNOJbc"
  
  # –ü–æ–∫–∞–∑–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
  python -m app.analyze_llm show "26riTPNOJbc"
  
  # –°–ø–∏—Å–æ–∫ –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –≤—ñ–¥–µ–æ
  python -m app.analyze_llm list
  
  # –û—á–∏—Å—Ç–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
  python -m app.analyze_llm clear --video "26riTPNOJbc"
  python -m app.analyze_llm clear --all
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–º–∞–Ω–¥–∏")
    
    # –ö–æ–º–∞–Ω–¥–∞ analyze
    analyze_parser = subparsers.add_parser("analyze", help="–ü—Ä–æ–≤–µ—Å—Ç–∏ –Ω–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑ –≤—ñ–¥–µ–æ")
    analyze_parser.add_argument("url", help="YouTube URL –∞–±–æ video_id")
    analyze_parser.add_argument("--sqlite", default="./.cache.db", help="–®–ª—è—Ö –¥–æ SQLite –∫–µ—à—É")
    analyze_parser.add_argument("--limit", type=int, default=1200, help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤")
    
    # –ö–æ–º–∞–Ω–¥–∞ show
    show_parser = subparsers.add_parser("show", help="–ü–æ–∫–∞–∑–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏")
    show_parser.add_argument("url", help="YouTube URL –∞–±–æ video_id")
    show_parser.add_argument("--sqlite", default="./.cache.db", help="–®–ª—è—Ö –¥–æ SQLite –∫–µ—à—É")
    
    # –ö–æ–º–∞–Ω–¥–∞ list
    list_parser = subparsers.add_parser("list", help="–ü–æ–∫–∞–∑–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –≤—ñ–¥–µ–æ")
    list_parser.add_argument("--sqlite", default="./.cache.db", help="–®–ª—è—Ö –¥–æ SQLite –∫–µ—à—É")
    
    # –ö–æ–º–∞–Ω–¥–∞ clear
    clear_parser = subparsers.add_parser("clear", help="–û—á–∏—Å—Ç–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏")
    clear_parser.add_argument("--video", help="URL –∞–±–æ video_id –¥–ª—è –æ—á–∏—â–µ–Ω–Ω—è (—è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ - –æ—á–∏—â–∞—î –≤—Å–µ)")
    clear_parser.add_argument("--all", action="store_true", help="–û—á–∏—Å—Ç–∏—Ç–∏ –≤—Å—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏")
    clear_parser.add_argument("--sqlite", default="./.cache.db", help="–®–ª—è—Ö –¥–æ SQLite –∫–µ—à—É")
    
    args = parser.parse_args()
    
    # –Ø–∫—â–æ –∫–æ–º–∞–Ω–¥–∞ –Ω–µ –≤–∫–∞–∑–∞–Ω–∞, –ø–æ–∫–∞–∑—É—î–º–æ help
    if not args.command:
        parser.print_help()
        return
    
    try:
        if args.command == "analyze":
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ API –∫–ª—é—á—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
            if not os.getenv("OPENROUTER_API_KEY"):
                print("‚ùå –ü–æ–º–∏–ª–∫–∞: –≤—ñ–¥—Å—É—Ç–Ω—è –∑–º—ñ–Ω–Ω–∞ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ OPENROUTER_API_KEY")
                print("üí° –î–æ–¥–∞–π—Ç–µ —ó—ó –≤ .env —Ñ–∞–π–ª –∞–±–æ –≤—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å —á–µ—Ä–µ–∑ export OPENROUTER_API_KEY=your_key")
                return
            
            if not os.getenv("YOUTUBE_API_KEY"):
                print("‚ö†Ô∏è  –ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è: –≤—ñ–¥—Å—É—Ç–Ω—è –∑–º—ñ–Ω–Ω–∞ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ YOUTUBE_API_KEY")
                print("üí° –ú–æ–∂–ª–∏–≤–æ, –∑–Ω–∞–¥–æ–±–∏—Ç—å—Å—è –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–æ–≤–∏—Ö –≤—ñ–¥–µ–æ")
            
            run(args.url, sqlite_path=args.sqlite, limit=args.limit)
            
        elif args.command == "show":
            show_saved_results(args.url, args.sqlite)
            
        elif args.command == "list":
            list_analyzed_videos(args.sqlite)
            
        elif args.command == "clear":
            if args.all:
                clear_results(None, args.sqlite)
            elif args.video:
                clear_results(args.video, args.sqlite)
            else:
                print("‚ùå –í–∫–∞–∂—ñ—Ç—å --video <URL> –∞–±–æ --all –¥–ª—è –æ—á–∏—â–µ–Ω–Ω—è")
                
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  –ó—É–ø–∏–Ω–µ–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
