#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü—ñ—ó –∫—É—Ä—Å–æ–≤–æ—ó —Ä–æ–±–æ—Ç–∏
YouTube Comment Consultant - –∞–Ω–∞–ª—ñ–∑ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º GenAI
"""

import matplotlib.pyplot as plt
import pandas as pd
import sqlite3
import numpy as np
import seaborn as sns
from datetime import datetime
import json

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è matplotlib –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç—É —Ç–∞ –≥–∞—Ä–Ω–æ–≥–æ –≤–∏–≥–ª—è–¥—É
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'Tahoma']
plt.rcParams['font.size'] = 12
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")

def load_latest_video_data(db_path=".cache.db"):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –¥–∞–Ω—ñ –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ–≥–æ –≤—ñ–¥–µ–æ."""
    
    with sqlite3.connect(db_path) as conn:
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—ñ–¥–µ–æ –∑ –¥–∞–Ω–∏–º–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ
        video_query = """
            SELECT cl.video_id, COUNT(cl.comment_id) as comment_count
            FROM comment_labels cl
            INNER JOIN sentiment_summary ss ON cl.video_id = ss.video_id
            GROUP BY cl.video_id 
            ORDER BY comment_count DESC 
            LIMIT 1
        """
        
        video_result = pd.read_sql_query(video_query, conn)
        if video_result.empty:
            raise ValueError("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –≤ –ë–î")
            
        video_id = video_result.iloc[0]['video_id']
        print(f"üìä –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –≤—ñ–¥–µ–æ: {video_id} ({video_result.iloc[0]['comment_count']} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤)")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤
        comments_query = """
            SELECT 
                cl.comment_id,
                cl.labels_json,
                cl.sentiment,
                cl.top_label,
                c.text as comment_text,
                c.like_count,
                c.published_at
            FROM comment_labels cl
            LEFT JOIN comments c ON cl.comment_id = c.comment_id
            WHERE cl.video_id = ?
        """
        
        comments_df = pd.read_sql_query(comments_query, conn, params=[video_id])
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–µ–º
        topics_query = """
            SELECT topic_id, count, share
            FROM topics_summary 
            WHERE video_id = ?
            ORDER BY count DESC
        """
        
        topics_df = pd.read_sql_query(topics_query, conn, params=[video_id])
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ
        sentiment_query = """
            SELECT sentiment, count, share
            FROM sentiment_summary 
            WHERE video_id = ?
        """
        
        sentiment_df = pd.read_sql_query(sentiment_query, conn, params=[video_id])
        
    return video_id, comments_df, topics_df, sentiment_df

def create_topics_distribution_chart(topics_df, video_id):
    """–°—Ç–≤–æ—Ä—é—î –∫—Ä—É–≥–æ–≤–∏–π –≥—Ä–∞—Ñ—ñ–∫ —Ä–æ–∑–ø–æ–¥—ñ–ª—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–π."""
    
    # –ú–∞–ø—ñ–Ω–≥ –Ω–∞–∑–≤ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
    topic_names = {
        'praise': '–ü–æ—Ö–≤–∞–ª–∞/–ø–æ–¥—è–∫–∞',
        'critique': '–ö—Ä–∏—Ç–∏–∫–∞/–Ω–µ–∑–∞–¥–æ–≤–æ–ª–µ–Ω–Ω—è', 
        'questions': '–ü–∏—Ç–∞–Ω–Ω—è/—É—Ç–æ—á–Ω–µ–Ω–Ω—è',
        'suggestions': '–ü–æ—Ä–∞–¥–∏/–ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—ó',
        'host_persona': '–í–µ–¥—É—á–∏–π/–ø–µ—Ä—Å–æ–Ω–∞',
        'content_truth': '–¢–æ—á–Ω—ñ—Å—Ç—å/–ø—Ä–∞–≤–¥–∏–≤—ñ—Å—Ç—å',
        'av_quality': '–ó–≤—É–∫/–≤—ñ–¥–µ–æ/–º–æ–Ω—Ç–∞–∂',
        'price_value': '–¶—ñ–Ω–∏/—Ü—ñ–Ω–Ω—ñ—Å—Ç—å',
        'personal_story': '–û—Å–æ–±–∏—Å—Ç—ñ —ñ—Å—Ç–æ—Ä—ñ—ó',
        'offtopic_fun': '–û—Ñ—Ç–æ–ø/–∂–∞—Ä—Ç–∏/–º–µ–º–∏',
        'toxicity': '–¢–æ–∫—Å–∏—á–Ω—ñ—Å—Ç—å/—Ö–µ–π—Ç'
    }
    
    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
    if topics_df.empty:
        print("‚ö†Ô∏è –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –ø—Ä–æ —Ç–µ–º–∏")
        return
        
    # –û–±—á–∏—Å–ª—é—î–º–æ –≤—ñ–¥—Å–æ—Ç–∫–∏ —ñ –±–µ—Ä–µ–º–æ —Ç–æ–ø-8 —Ç–µ–º –¥–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—ñ
    topics_df['share_percent'] = topics_df['share'] * 100
    top_topics = topics_df.head(8).copy()
    top_topics['topic_name'] = top_topics['topic_id'].map(topic_names)
    top_topics['topic_name'] = top_topics['topic_name'].fillna(top_topics['topic_id'])
    
    # –Ø–∫—â–æ —î —ñ–Ω—à—ñ —Ç–µ–º–∏, –≥—Ä—É–ø—É—î–º–æ —ó—Ö
    if len(topics_df) > 8:
        others_count = topics_df.iloc[8:]['count'].sum()
        others_row = pd.DataFrame({
            'topic_id': ['others'],
            'topic_name': ['–Ü–Ω—à–µ'],
            'count': [others_count],
            'share_percent': [others_count / topics_df['count'].sum() * 100]
        })
        top_topics = pd.concat([top_topics, others_row], ignore_index=True)
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—É
    fig, ax = plt.subplots(figsize=(12, 8))
    
    colors = plt.cm.Set3(np.linspace(0, 1, len(top_topics)))
    
    wedges, texts, autotexts = ax.pie(
        top_topics['count'], 
        labels=top_topics['topic_name'],
        autopct='%1.1f%%',
        startangle=90,
        colors=colors,
        textprops={'fontsize': 10}
    )
    
    # –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≤–∏–≥–ª—è–¥—É
    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_fontweight('bold')
        autotext.set_fontsize(9)
    
    for text in texts:
        text.set_fontsize(9)
    
    ax.set_title(f'–†–æ–∑–ø–æ–¥—ñ–ª –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤\n–í—ñ–¥–µ–æ: {video_id}', 
                fontsize=16, fontweight='bold', pad=20)
    
    # –î–æ–¥–∞—î–º–æ –ª–µ–≥–µ–Ω–¥—É –∑ –∫—ñ–ª—å–∫—ñ—Å—Ç—é
    legend_labels = [f'{name} ({count})' for name, count in 
                    zip(top_topics['topic_name'], top_topics['count'])]
    ax.legend(wedges, legend_labels, title="–ö–∞—Ç–µ–≥–æ—Ä—ñ—ó", 
             loc="center left", bbox_to_anchor=(1, 0, 0.5, 1), fontsize=9)
    
    plt.tight_layout()
    plt.savefig('topics_distribution.png', dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    plt.close()
    print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: topics_distribution.png")

def create_sentiment_analysis_chart(sentiment_df, comments_df, video_id):
    """–°—Ç–≤–æ—Ä—é—î –≥—Ä–∞—Ñ—ñ–∫ –∞–Ω–∞–ª—ñ–∑—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ."""
    
    if sentiment_df.empty:
        print("‚ö†Ô∏è –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –ø—Ä–æ —Ç–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å")
        return
    
    # –ú–∞–ø—ñ–Ω–≥ –Ω–∞–∑–≤ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ
    sentiment_names = {
        'positive': '–ü–æ–∑–∏—Ç–∏–≤–Ω–∞',
        'neutral': '–ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞', 
        'negative': '–ù–µ–≥–∞—Ç–∏–≤–Ω–∞'
    }
    
    sentiment_colors = {
        'positive': '#2ecc71',   # –ó–µ–ª–µ–Ω–∏–π
        'neutral': '#95a5a6',    # –°—ñ—Ä–∏–π
        'negative': '#e74c3c'    # –ß–µ—Ä–≤–æ–Ω–∏–π
    }
    
    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
    sentiment_df = sentiment_df.copy()
    sentiment_df['sentiment_name'] = sentiment_df['sentiment'].map(sentiment_names)
    sentiment_df['color'] = sentiment_df['sentiment'].map(sentiment_colors)
    sentiment_df['percentage'] = sentiment_df['share'] * 100
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—É–±–ø–ª–æ—Ç—ñ–≤
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'–ê–Ω–∞–ª—ñ–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤\n–í—ñ–¥–µ–æ: {video_id}', 
                fontsize=18, fontweight='bold')
    
    # 1. –ö—Ä—É–≥–æ–≤–∏–π –≥—Ä–∞—Ñ—ñ–∫ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ
    wedges, texts, autotexts = ax1.pie(
        sentiment_df['count'],
        labels=sentiment_df['sentiment_name'],
        autopct='%1.1f%%',
        colors=sentiment_df['color'],
        startangle=90,
        textprops={'fontsize': 11}
    )
    
    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_fontweight('bold')
    
    ax1.set_title('–†–æ–∑–ø–æ–¥—ñ–ª —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ', fontsize=14, fontweight='bold')
    
    # 2. –°—Ç–æ–≤–ø—á–∏–∫–æ–≤–∞ –¥—ñ–∞–≥—Ä–∞–º–∞
    bars = ax2.bar(sentiment_df['sentiment_name'], sentiment_df['count'], 
                   color=sentiment_df['color'], alpha=0.8, edgecolor='black', linewidth=1)
    
    # –î–æ–¥–∞—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞ —Å—Ç–æ–≤–ø—á–∏–∫–∏
    for bar, count in zip(bars, sentiment_df['count']):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{count}', ha='center', va='bottom', fontweight='bold')
    
    ax2.set_title('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ –∑–∞ —Ç–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—é', fontsize=14, fontweight='bold')
    ax2.set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤')
    ax2.grid(axis='y', alpha=0.3)
    
    # 3. –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞ –¥—ñ–∞–≥—Ä–∞–º–∞ –∑ –≤—ñ–¥—Å–æ—Ç–∫–∞–º–∏
    y_pos = np.arange(len(sentiment_df))
    bars_h = ax3.barh(y_pos, sentiment_df['percentage'], 
                      color=sentiment_df['color'], alpha=0.8, edgecolor='black', linewidth=1)
    
    ax3.set_yticks(y_pos)
    ax3.set_yticklabels(sentiment_df['sentiment_name'])
    ax3.set_xlabel('–í—ñ–¥—Å–æ—Ç–æ–∫ (%)')
    ax3.set_title('–í—ñ–¥—Å–æ—Ç–∫–æ–≤—ñ —á–∞—Å—Ç–∫–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ', fontsize=14, fontweight='bold')
    ax3.grid(axis='x', alpha=0.3)
    
    # –î–æ–¥–∞—î–º–æ –≤—ñ–¥—Å–æ—Ç–∫–∏
    for i, (bar, pct) in enumerate(zip(bars_h, sentiment_df['percentage'])):
        ax3.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,
                f'{pct:.1f}%', ha='left', va='center', fontweight='bold')
    
    # 4. –¢–∞–±–ª–∏—Ü—è –∑—ñ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ—é
    ax4.axis('tight')
    ax4.axis('off')
    
    table_data = []
    total_comments = sentiment_df['count'].sum()
    
    for _, row in sentiment_df.iterrows():
        table_data.append([
            row['sentiment_name'],
            f"{row['count']}",
            f"{row['percentage']:.1f}%"
        ])
    
    # –î–æ–¥–∞—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É —Å—É–º—É
    table_data.append(['–í—Å—å–æ–≥–æ', f"{total_comments}", "100.0%"])
    
    table = ax4.table(cellText=table_data,
                     colLabels=['–¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å', '–ö—ñ–ª—å–∫—ñ—Å—Ç—å', '–í—ñ–¥—Å–æ—Ç–æ–∫'],
                     cellLoc='center',
                     loc='center',
                     colWidths=[0.4, 0.3, 0.3])
    
    table.auto_set_font_size(False)
    table.set_fontsize(11)
    table.scale(1.2, 2)
    
    # –°—Ç–∏–ª—ñ–∑–∞—Ü—ñ—è —Ç–∞–±–ª–∏—Ü—ñ
    for i in range(len(table_data)):
        for j in range(3):
            cell = table[(i+1, j)]
            if i < len(sentiment_df):
                color = sentiment_df.iloc[i]['color']
                cell.set_facecolor(color)
                cell.set_alpha(0.3)
            else:  # –ó–∞–≥–∞–ª—å–Ω–∞ —Å—É–º–∞
                cell.set_facecolor('#34495e')
                cell.set_alpha(0.7)
                cell.set_text_props(weight='bold', color='white')
    
    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ñ
    for j in range(3):
        cell = table[(0, j)]
        cell.set_facecolor('#2c3e50')
        cell.set_text_props(weight='bold', color='white')
    
    ax4.set_title('–î–µ—Ç–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('sentiment_analysis.png', dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.close()
    print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: sentiment_analysis.png")

def create_combined_overview_chart(topics_df, sentiment_df, video_id):
    """–°—Ç–≤–æ—Ä—é—î –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π –æ–≥–ª—è–¥ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü—ñ—ó."""
    
    if topics_df.empty or sentiment_df.empty:
        print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–æ–≥–æ –≥—Ä–∞—Ñ—ñ–∫—É")
        return
    
    # –ú–∞–ø—ñ–Ω–≥–∏
    topic_names = {
        'praise': '–ü–æ—Ö–≤–∞–ª–∞/–ø–æ–¥—è–∫–∞',
        'critique': '–ö—Ä–∏—Ç–∏–∫–∞/–Ω–µ–∑–∞–¥–æ–≤–æ–ª–µ–Ω–Ω—è', 
        'questions': '–ü–∏—Ç–∞–Ω–Ω—è/—É—Ç–æ—á–Ω–µ–Ω–Ω—è',
        'suggestions': '–ü–æ—Ä–∞–¥–∏/–ø—Ä–æ–ø–æ–∑–∏—Ü—ñ—ó',
        'host_persona': '–í–µ–¥—É—á–∏–π/–ø–µ—Ä—Å–æ–Ω–∞',
        'content_truth': '–¢–æ—á–Ω—ñ—Å—Ç—å/–ø—Ä–∞–≤–¥–∏–≤—ñ—Å—Ç—å',
        'av_quality': '–ó–≤—É–∫/–≤—ñ–¥–µ–æ/–º–æ–Ω—Ç–∞–∂',
        'price_value': '–¶—ñ–Ω–∏/—Ü—ñ–Ω–Ω—ñ—Å—Ç—å',
        'personal_story': '–û—Å–æ–±–∏—Å—Ç—ñ —ñ—Å—Ç–æ—Ä—ñ—ó',
        'offtopic_fun': '–û—Ñ—Ç–æ–ø/–∂–∞—Ä—Ç–∏/–º–µ–º–∏',
        'toxicity': '–¢–æ–∫—Å–∏—á–Ω—ñ—Å—Ç—å/—Ö–µ–π—Ç'
    }
    
    sentiment_names = {
        'positive': '–ü–æ–∑–∏—Ç–∏–≤–Ω–∞',
        'neutral': '–ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞', 
        'negative': '–ù–µ–≥–∞—Ç–∏–≤–Ω–∞'
    }
    
    sentiment_colors = {
        'positive': '#2ecc71',
        'neutral': '#95a5a6',
        'negative': '#e74c3c'
    }
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    fig.suptitle(f'–û–≥–ª—è–¥ –∞–Ω–∞–ª—ñ–∑—É –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤ - YouTube Comment Consultant\n–í—ñ–¥–µ–æ: {video_id}', 
                fontsize=16, fontweight='bold')
    
    # 1. –¢–æ–ø-6 –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
    top_topics = topics_df.head(6).copy()
    top_topics['topic_name'] = top_topics['topic_id'].map(topic_names)
    top_topics['topic_name'] = top_topics['topic_name'].fillna(top_topics['topic_id'])
    
    # –°–∫–æ—Ä–æ—á—É—î–º–æ –¥–æ–≤–≥—ñ –Ω–∞–∑–≤–∏ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    top_topics['short_name'] = top_topics['topic_name'].str.replace('/', '/\n')
    
    bars1 = ax1.bar(range(len(top_topics)), top_topics['count'], 
                   color=plt.cm.Set3(np.linspace(0, 1, len(top_topics))),
                   alpha=0.8, edgecolor='black', linewidth=1)
    
    ax1.set_xticks(range(len(top_topics)))
    ax1.set_xticklabels(top_topics['short_name'], rotation=45, ha='right', fontsize=10)
    ax1.set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤')
    ax1.set_title('–¢–æ–ø-6 –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤', fontsize=14, fontweight='bold')
    ax1.grid(axis='y', alpha=0.3)
    
    # –î–æ–¥–∞—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞ —Å—Ç–æ–≤–ø—á–∏–∫–∏
    for bar, count in zip(bars1, top_topics['count']):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.3,
                f'{count}', ha='center', va='bottom', fontweight='bold', fontsize=10)
    
    # 2. –¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å
    sentiment_df_copy = sentiment_df.copy()
    sentiment_df_copy['sentiment_name'] = sentiment_df_copy['sentiment'].map(sentiment_names)
    sentiment_df_copy['color'] = sentiment_df_copy['sentiment'].map(sentiment_colors)
    sentiment_df_copy['percentage'] = sentiment_df_copy['share'] * 100
    
    wedges, texts, autotexts = ax2.pie(
        sentiment_df_copy['count'],
        labels=sentiment_df_copy['sentiment_name'],
        autopct='%1.1f%%',
        colors=sentiment_df_copy['color'],
        startangle=90,
        textprops={'fontsize': 12}
    )
    
    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_fontweight('bold')
        autotext.set_fontsize(11)
    
    ax2.set_title('–†–æ–∑–ø–æ–¥—ñ–ª —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ', fontsize=14, fontweight='bold')
    
    # –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø—Ä–æ—î–∫—Ç
    total_comments = sentiment_df['count'].sum()
    info_text = f"""GenAI Technologies Used:
‚Ä¢ OpenRouter API (GPT-4o-mini, Gemini-2.5-Flash)  
‚Ä¢ Function Calling –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
‚Ä¢ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è —Ç–µ–º —ñ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ
‚Ä¢ Telegram Bot –∑ AI-–∞–≥–µ–Ω—Ç–æ–º

–í—Å—å–æ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ: {total_comments} –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤"""
    
    fig.text(0.02, 0.02, info_text, fontsize=9, va='bottom', 
            bbox=dict(boxstyle="round,pad=0.5", facecolor='lightgray', alpha=0.8))
    
    plt.tight_layout()
    plt.subplots_adjust(bottom=0.15)
    plt.savefig('overview_presentation.png', dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.close()
    print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: overview_presentation.png")

def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—Å—ñ—Ö –≥—Ä–∞—Ñ—ñ–∫—ñ–≤."""
    
    print("üé® –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü—ñ—ó –∫—É—Ä—Å–æ–≤–æ—ó —Ä–æ–±–æ—Ç–∏...")
    print("üìä YouTube Comment Consultant - GenAI –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ–≤\n")
    
    try:
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ
        video_id, comments_df, topics_df, sentiment_df = load_latest_video_data()
        
        print(f"üìà –î–∞–Ω—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ:")
        print(f"   –ö–æ–º–µ–Ω—Ç–∞—Ä—ñ: {len(comments_df)}")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä—ñ—ó: {len(topics_df)}")
        print(f"   –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ: {len(sentiment_df)}\n")
        
        # –ì–µ–Ω–µ—Ä—É—î–º–æ –≥—Ä–∞—Ñ—ñ–∫–∏
        print("üé® –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤...")
        
        create_topics_distribution_chart(topics_df, video_id)
        create_sentiment_analysis_chart(sentiment_df, comments_df, video_id)
        create_combined_overview_chart(topics_df, sentiment_df, video_id)
        
        print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! –°—Ç–≤–æ—Ä–µ–Ω–æ 3 –≥—Ä–∞—Ñ—ñ–∫–∏:")
        print("   üìä topics_distribution.png - –†–æ–∑–ø–æ–¥—ñ–ª –∫–∞—Ç–µ–≥–æ—Ä—ñ–π")
        print("   üòä sentiment_analysis.png - –ê–Ω–∞–ª—ñ–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ") 
        print("   üìà overview_presentation.png - –ó–∞–≥–∞–ª—å–Ω–∏–π –æ–≥–ª—è–¥")
        print(f"\nüí° –ì—Ä–∞—Ñ—ñ–∫–∏ –≥–æ—Ç–æ–≤—ñ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –≤ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü—ñ—é!")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
